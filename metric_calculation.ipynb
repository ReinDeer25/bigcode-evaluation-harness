{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\code\\bigcode-evaluation-harness\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import random\n",
    "from datasets import load_dataset,concatenate_datasets, Dataset\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def sampling(dataset,target,pos_n_sample,neg_n_sample,seed=0):\n",
    "    random.seed(seed)\n",
    "    neg_ds = dataset.filter(lambda example: example[target]==False or example[target] == \"0\")\n",
    "    pos_ds = dataset.filter(lambda example: example[target]==True or example[target] == \"1\")\n",
    "    neg_sampled_indices = random.sample(range(0, len(neg_ds)), neg_n_sample)\n",
    "    pos_sampled_indices = random.sample(range(0, len(pos_ds)), pos_n_sample)\n",
    "    neg_selected_ds = neg_ds.select(neg_sampled_indices)\n",
    "    pos_selected_ds = pos_ds.select(pos_sampled_indices)\n",
    "    combined_ds = concatenate_datasets([neg_selected_ds, pos_selected_ds]).shuffle(seed=seed)\n",
    "    return combined_ds\n",
    "\n",
    "def filter_valid(preds, labels):\n",
    "    filtered_label, filtered_pred = zip(*[(label, pred) for pred, label in zip(preds, labels) if pred != '-1'])\n",
    "    return filtered_label, filtered_pred\n",
    "\n",
    "def rearrange_string(s):\n",
    "    parts = s.split('-')\n",
    "    return '-'.join([parts[1], parts[0]])\n",
    "\n",
    "def calculate_valid(preds,labels):\n",
    "    try:\n",
    "        filtered_labels, filtered_preds = filter_valid(preds, labels)\n",
    "    except ValueError:\n",
    "        filtered_labels, filtered_preds = [],[]\n",
    "        valid_acc,valid_f1,valid_rec = 0,0,0\n",
    "    else:\n",
    "        valid_acc = accuracy_metric.compute(predictions=filtered_preds, references=filtered_labels)['accuracy']*100\n",
    "        valid_f1 = f1_metric.compute(predictions=filtered_preds, references=filtered_labels)['f1']*100\n",
    "        valid_rec = len(filtered_labels)/len(labels)*100\n",
    "    return valid_acc,valid_f1,valid_rec\n",
    "\n",
    "def calculate_overall(preds,labels):\n",
    "    acc = accuracy_metric.compute(predictions=preds, references=labels)['accuracy']*100\n",
    "    f1_macro = f1_metric.compute(predictions=preds, references=labels,average='macro' )['f1']*100\n",
    "    return acc,f1_macro\n",
    "\n",
    "def contains_keyword(sentence, keywords):\n",
    "    for keyword in keywords:\n",
    "        if keyword.lower() in sentence.lower():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def paper_method(raw_texts,positive_kw,negative_kw):\n",
    "    preds_list =[]\n",
    "    for text in raw_texts:\n",
    "        short_ans = text.lower().replace(',','.').split('.')[0]\n",
    "        if 'yes' in short_ans and 'no' not in short_ans:\n",
    "            preds_list.append(\"1\")\n",
    "        elif 'no' in short_ans and 'yes' not in short_ans:\n",
    "            preds_list.append(\"0\")\n",
    "        elif contains_keyword(text, positive_kw):\n",
    "            preds_list.append(\"1\")\n",
    "        elif contains_keyword(text, negative_kw):\n",
    "            preds_list.append(\"0\")\n",
    "        else:\n",
    "            preds_list.append(\"-1\")\n",
    "    return preds_list\n",
    "\n",
    "def summary_table(file_list,path,labels,positive_kw,negative_kw):\n",
    "    df = pd.DataFrame(columns=['experiment', '%overall_acc','%overall_f1_macro','%valid_rec' ,'%valid_acc', '%valid_f1'])\n",
    "    for file in file_list:\n",
    "        try:\n",
    "            with open(path[0]+file+path[1], 'r') as f:\n",
    "                data = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        else:         \n",
    "            raw_texts = [text[0]['raw_text'].split(\"\\nAnswer:\")[-1] for text in data]\n",
    "            preds = paper_method(raw_texts,positive_kw,negative_kw)\n",
    "            acc,f1_macro = calculate_overall(preds,labels)\n",
    "            valid_acc,valid_f1,valid_rec = calculate_valid(preds,labels)\n",
    "\n",
    "            df.loc[len(df)] = {'experiment': rearrange_string(file), \n",
    "                               '%overall_acc':round(acc, 2),\n",
    "                               '%overall_f1_macro':round(f1_macro, 2),\n",
    "                               '%valid_rec':round(valid_rec, 2) ,\n",
    "                               '%valid_acc':round(valid_acc, 2), \n",
    "                               '%valid_f1':round(valid_f1, 2)}\n",
    "    return df\n",
    "\n",
    "def summary_table_sampling(file_list,path,pos_n_sample,neg_n_sample,positive_kw,negative_kw):\n",
    "    df = pd.DataFrame(columns=['experiment', '%overall_acc','%overall_f1_macro','%valid_rec' ,'%valid_acc', '%valid_f1'])\n",
    "    for file in file_list:\n",
    "        try:\n",
    "            with open(path[0]+file+path[1], 'r') as f:\n",
    "                data = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        else:\n",
    "            data = [content[0] for content in data]\n",
    "            dataset_clean = Dataset.from_pandas(pd.DataFrame(data=data))\n",
    "            data = sampling(dataset_clean,\"true_label\",pos_n_sample,neg_n_sample)\n",
    "            \n",
    "            labels = [label['true_label'] for label in data]\n",
    "            raw_texts = [text['raw_text'].split(\"\\nAnswer:\")[-1] for text in data]\n",
    "            preds = paper_method(raw_texts,positive_kw,negative_kw)\n",
    "            acc,f1_macro = calculate_overall(preds,labels)\n",
    "            valid_acc,valid_f1,valid_rec = calculate_valid(preds,labels)\n",
    "\n",
    "            df.loc[len(df)] = {'experiment': rearrange_string(file), \n",
    "                               '%overall_acc':round(acc, 2),\n",
    "                               '%overall_f1_macro':round(f1_macro, 2),\n",
    "                               '%valid_rec':round(valid_rec, 2) ,\n",
    "                               '%valid_acc':round(valid_acc, 2), \n",
    "                               '%valid_f1':round(valid_f1, 2)}\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['1b', '3b', '7b', '15b']\n",
    "methods = ['lora','adalora','ia3','prompt','ptuning','parallel','adapterp','adapterh','fft']\n",
    "file_list = [f\"{model}-{method}\" for method in methods for model in models]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defect detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defect detection formatB\n",
    "instruction = '''Is there a defect in the Code, and respond to YES or NO.''' <br>\n",
    "prompt= f'''Question: {instruction}\\n{code}\\n\\nAnswer:'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defect detection formatA\n",
    "instruction = '''Is there a defect in the Code, and respond to YES or NO.''' <br>\n",
    "prompt= f'''Question: {instruction}\\n{code}\\n\\nAnswer:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defect detection formatA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 68663.49 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 95011.31 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 85030.19 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 76774.08 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 120328.03 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 116899.49 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 131886.64 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 102765.24 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 118743.21 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 101595.36 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 153931.82 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 107720.15 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 112463.94 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 104790.48 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 122098.67 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 93433.23 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 115800.82 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 89056.72 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 98852.97 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 108343.47 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 101338.39 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 99220.17 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 121663.09 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 97066.85 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 122097.37 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 98311.87 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 137754.57 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 121144.74 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 142439.60 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 152972.16 examples/s]\n",
      "c:\\Users\\User\\Desktop\\code\\bigcode-evaluation-harness\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 120958.04 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 136854.63 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 137551.18 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 131246.15 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 191063.44 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 118150.63 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 129475.48 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 121988.19 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 122090.87 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 146022.69 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 161221.79 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 127690.73 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 146568.07 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 110630.04 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 184089.56 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 101213.08 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 149953.39 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 141188.25 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 117394.10 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 116545.18 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 156285.30 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 140469.98 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 178617.34 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 116643.65 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 149900.43 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 112369.10 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 146035.72 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 126200.05 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 121577.90 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 160218.66 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 128606.49 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 110243.68 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 224357.57 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 115797.31 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 124770.94 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 140908.73 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 139537.73 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 125096.49 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 144949.51 examples/s]\n",
      "Filter: 100%|██████████| 2732/2732 [00:00<00:00, 98051.09 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>%overall_acc</th>\n",
       "      <th>%overall_f1_macro</th>\n",
       "      <th>%valid_rec</th>\n",
       "      <th>%valid_acc</th>\n",
       "      <th>%valid_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lora-1b</td>\n",
       "      <td>44.15</td>\n",
       "      <td>21.49</td>\n",
       "      <td>97.60</td>\n",
       "      <td>45.24</td>\n",
       "      <td>61.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lora-3b</td>\n",
       "      <td>44.90</td>\n",
       "      <td>20.98</td>\n",
       "      <td>98.55</td>\n",
       "      <td>45.56</td>\n",
       "      <td>62.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lora-7b</td>\n",
       "      <td>49.05</td>\n",
       "      <td>47.27</td>\n",
       "      <td>100.00</td>\n",
       "      <td>49.05</td>\n",
       "      <td>56.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora-15b</td>\n",
       "      <td>47.20</td>\n",
       "      <td>31.67</td>\n",
       "      <td>98.60</td>\n",
       "      <td>47.87</td>\n",
       "      <td>46.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adalora-1b</td>\n",
       "      <td>53.20</td>\n",
       "      <td>29.90</td>\n",
       "      <td>97.00</td>\n",
       "      <td>54.85</td>\n",
       "      <td>22.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adalora-3b</td>\n",
       "      <td>28.35</td>\n",
       "      <td>18.52</td>\n",
       "      <td>48.90</td>\n",
       "      <td>57.98</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>adalora-7b</td>\n",
       "      <td>36.90</td>\n",
       "      <td>20.26</td>\n",
       "      <td>67.40</td>\n",
       "      <td>54.75</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adalora-15b</td>\n",
       "      <td>21.55</td>\n",
       "      <td>15.75</td>\n",
       "      <td>37.15</td>\n",
       "      <td>58.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ia3-1b</td>\n",
       "      <td>53.90</td>\n",
       "      <td>28.92</td>\n",
       "      <td>97.75</td>\n",
       "      <td>55.14</td>\n",
       "      <td>18.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ia3-3b</td>\n",
       "      <td>33.55</td>\n",
       "      <td>20.07</td>\n",
       "      <td>59.35</td>\n",
       "      <td>56.53</td>\n",
       "      <td>2.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ia3-7b</td>\n",
       "      <td>37.20</td>\n",
       "      <td>20.30</td>\n",
       "      <td>68.10</td>\n",
       "      <td>54.63</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>prompt-1b</td>\n",
       "      <td>25.10</td>\n",
       "      <td>16.71</td>\n",
       "      <td>54.70</td>\n",
       "      <td>45.89</td>\n",
       "      <td>62.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>prompt-3b</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>prompt-7b</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.15</td>\n",
       "      <td>66.67</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>prompt-15b</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ptuning-1b</td>\n",
       "      <td>53.70</td>\n",
       "      <td>25.66</td>\n",
       "      <td>98.85</td>\n",
       "      <td>54.32</td>\n",
       "      <td>7.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ptuning-3b</td>\n",
       "      <td>27.75</td>\n",
       "      <td>18.19</td>\n",
       "      <td>47.65</td>\n",
       "      <td>58.24</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ptuning-7b</td>\n",
       "      <td>40.55</td>\n",
       "      <td>21.40</td>\n",
       "      <td>72.30</td>\n",
       "      <td>56.09</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ptuning-15b</td>\n",
       "      <td>10.75</td>\n",
       "      <td>9.67</td>\n",
       "      <td>20.10</td>\n",
       "      <td>53.48</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>parallel-1b</td>\n",
       "      <td>34.50</td>\n",
       "      <td>22.32</td>\n",
       "      <td>72.95</td>\n",
       "      <td>47.29</td>\n",
       "      <td>61.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>parallel-3b</td>\n",
       "      <td>33.50</td>\n",
       "      <td>26.32</td>\n",
       "      <td>68.75</td>\n",
       "      <td>48.73</td>\n",
       "      <td>52.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>parallel-7b</td>\n",
       "      <td>52.60</td>\n",
       "      <td>34.83</td>\n",
       "      <td>97.40</td>\n",
       "      <td>54.00</td>\n",
       "      <td>45.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>parallel-15b</td>\n",
       "      <td>46.10</td>\n",
       "      <td>30.61</td>\n",
       "      <td>97.65</td>\n",
       "      <td>47.21</td>\n",
       "      <td>52.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>adapterp-1b</td>\n",
       "      <td>45.70</td>\n",
       "      <td>23.29</td>\n",
       "      <td>99.35</td>\n",
       "      <td>46.00</td>\n",
       "      <td>61.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>adapterp-3b</td>\n",
       "      <td>46.05</td>\n",
       "      <td>21.34</td>\n",
       "      <td>99.95</td>\n",
       "      <td>46.07</td>\n",
       "      <td>62.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>adapterp-7b</td>\n",
       "      <td>46.85</td>\n",
       "      <td>25.32</td>\n",
       "      <td>99.95</td>\n",
       "      <td>46.87</td>\n",
       "      <td>61.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>adapterp-15b</td>\n",
       "      <td>48.05</td>\n",
       "      <td>32.34</td>\n",
       "      <td>97.75</td>\n",
       "      <td>49.16</td>\n",
       "      <td>47.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>adapterh-1b</td>\n",
       "      <td>45.75</td>\n",
       "      <td>20.99</td>\n",
       "      <td>99.75</td>\n",
       "      <td>45.86</td>\n",
       "      <td>62.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>adapterh-3b</td>\n",
       "      <td>45.80</td>\n",
       "      <td>21.00</td>\n",
       "      <td>99.80</td>\n",
       "      <td>45.89</td>\n",
       "      <td>62.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>adapterh-7b</td>\n",
       "      <td>46.25</td>\n",
       "      <td>23.25</td>\n",
       "      <td>99.45</td>\n",
       "      <td>46.51</td>\n",
       "      <td>62.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>adapterh-15b</td>\n",
       "      <td>41.75</td>\n",
       "      <td>20.15</td>\n",
       "      <td>92.60</td>\n",
       "      <td>45.09</td>\n",
       "      <td>62.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>fft-1b</td>\n",
       "      <td>50.80</td>\n",
       "      <td>33.40</td>\n",
       "      <td>99.80</td>\n",
       "      <td>50.90</td>\n",
       "      <td>56.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>fft-3b</td>\n",
       "      <td>44.20</td>\n",
       "      <td>23.77</td>\n",
       "      <td>97.60</td>\n",
       "      <td>45.29</td>\n",
       "      <td>60.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>fft-7b</td>\n",
       "      <td>48.30</td>\n",
       "      <td>29.30</td>\n",
       "      <td>99.95</td>\n",
       "      <td>48.32</td>\n",
       "      <td>59.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>fft-15b</td>\n",
       "      <td>48.35</td>\n",
       "      <td>32.24</td>\n",
       "      <td>99.95</td>\n",
       "      <td>48.37</td>\n",
       "      <td>48.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      experiment  %overall_acc  %overall_f1_macro  %valid_rec  %valid_acc  \\\n",
       "0        lora-1b         44.15              21.49       97.60       45.24   \n",
       "1        lora-3b         44.90              20.98       98.55       45.56   \n",
       "2        lora-7b         49.05              47.27      100.00       49.05   \n",
       "3       lora-15b         47.20              31.67       98.60       47.87   \n",
       "4     adalora-1b         53.20              29.90       97.00       54.85   \n",
       "5     adalora-3b         28.35              18.52       48.90       57.98   \n",
       "6     adalora-7b         36.90              20.26       67.40       54.75   \n",
       "7    adalora-15b         21.55              15.75       37.15       58.01   \n",
       "8         ia3-1b         53.90              28.92       97.75       55.14   \n",
       "9         ia3-3b         33.55              20.07       59.35       56.53   \n",
       "10        ia3-7b         37.20              20.30       68.10       54.63   \n",
       "11     prompt-1b         25.10              16.71       54.70       45.89   \n",
       "12     prompt-3b          0.00               0.00        0.05        0.00   \n",
       "13     prompt-7b          0.10               0.13        0.15       66.67   \n",
       "14    prompt-15b          0.10               0.12        0.10      100.00   \n",
       "15    ptuning-1b         53.70              25.66       98.85       54.32   \n",
       "16    ptuning-3b         27.75              18.19       47.65       58.24   \n",
       "17    ptuning-7b         40.55              21.40       72.30       56.09   \n",
       "18   ptuning-15b         10.75               9.67       20.10       53.48   \n",
       "19   parallel-1b         34.50              22.32       72.95       47.29   \n",
       "20   parallel-3b         33.50              26.32       68.75       48.73   \n",
       "21   parallel-7b         52.60              34.83       97.40       54.00   \n",
       "22  parallel-15b         46.10              30.61       97.65       47.21   \n",
       "23   adapterp-1b         45.70              23.29       99.35       46.00   \n",
       "24   adapterp-3b         46.05              21.34       99.95       46.07   \n",
       "25   adapterp-7b         46.85              25.32       99.95       46.87   \n",
       "26  adapterp-15b         48.05              32.34       97.75       49.16   \n",
       "27   adapterh-1b         45.75              20.99       99.75       45.86   \n",
       "28   adapterh-3b         45.80              21.00       99.80       45.89   \n",
       "29   adapterh-7b         46.25              23.25       99.45       46.51   \n",
       "30  adapterh-15b         41.75              20.15       92.60       45.09   \n",
       "31        fft-1b         50.80              33.40       99.80       50.90   \n",
       "32        fft-3b         44.20              23.77       97.60       45.29   \n",
       "33        fft-7b         48.30              29.30       99.95       48.32   \n",
       "34       fft-15b         48.35              32.24       99.95       48.37   \n",
       "\n",
       "    %valid_f1  \n",
       "0       61.78  \n",
       "1       62.47  \n",
       "2       56.95  \n",
       "3       46.74  \n",
       "4       22.89  \n",
       "5        1.44  \n",
       "6        0.00  \n",
       "7        0.00  \n",
       "8       18.57  \n",
       "9        2.27  \n",
       "10       0.00  \n",
       "11      62.81  \n",
       "12       0.00  \n",
       "13      66.67  \n",
       "14       0.00  \n",
       "15       7.57  \n",
       "16       0.00  \n",
       "17       0.00  \n",
       "18       0.00  \n",
       "19      61.57  \n",
       "20      52.46  \n",
       "21      45.89  \n",
       "22      52.77  \n",
       "23      61.72  \n",
       "24      62.93  \n",
       "25      61.47  \n",
       "26      47.01  \n",
       "27      62.86  \n",
       "28      62.89  \n",
       "29      62.38  \n",
       "30      62.12  \n",
       "31      56.25  \n",
       "32      60.33  \n",
       "33      59.60  \n",
       "34      48.50  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defect_positive = ['there is a','ere is a','has a defect','contains a defect']\n",
    "defect_negative = ['there is no defect','The code is correct']\n",
    "\n",
    "dd_path = ['.\\\\run_result\\\\defect_generations_','_fullA.json']\n",
    "\n",
    "print(\"defect detection formatA\")\n",
    "summary_table_sampling(file_list,dd_path,919,1081,defect_positive,defect_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with open(\\'.\\\\run_result\\\\defect_generations_15b-ptuning_A.json\\', \\'r\\') as f:\\n    data = json.load(f)\\n\\ndefect_positive = [\\'there is a\\',\\'ere is a\\',\\'has a defect\\',\\'contains a defect\\']\\ndefect_negative = [\\'there is no defect\\', \\'The code is correct\\']        \\nraw_texts = [text[0][\\'raw_text\\'].split(\"\\nAnswer:\")[-1] for text in data]\\npaper_preds = paper_method(raw_texts,defect_positive,defect_negative)\\npreds = [label[0][\"prediction\"]for label in data]\\ntrue_labels = [label[0][\"true_label\"]for label in data]\\n\\ndf = pd.DataFrame({\\n    \\'true_labels\\': true_labels,\\n    \\'raw_texts\\': raw_texts,\\n    \\'paper_preds\\': paper_preds,\\n    \\'preds\\': preds,\\n})\\nfiltered_df = df[df[\\'paper_preds\\'] == \\'-1\\']\\nfiltered_df'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check invalid prediction\n",
    "\n",
    "'''with open('.\\\\run_result\\\\defect_generations_15b-ptuning_A.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "defect_positive = ['there is a','ere is a','has a defect','contains a defect']\n",
    "defect_negative = ['there is no defect', 'The code is correct']        \n",
    "raw_texts = [text[0]['raw_text'].split(\"\\nAnswer:\")[-1] for text in data]\n",
    "paper_preds = paper_method(raw_texts,defect_positive,defect_negative)\n",
    "preds = [label[0][\"prediction\"]for label in data]\n",
    "true_labels = [label[0][\"true_label\"]for label in data]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'true_labels': true_labels,\n",
    "    'raw_texts': raw_texts,\n",
    "    'paper_preds': paper_preds,\n",
    "    'preds': preds,\n",
    "})\n",
    "filtered_df = df[df['paper_preds'] == '-1']\n",
    "filtered_df'''\n",
    "#filtered_df.to_csv('invalid_15b_ptuning.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clone detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clone detection formatB\n",
    "instruction= '''Is there a clone relation between the Code1 and Code2, and respond to YES or NO.''' <br>\n",
    "code1= doc['func1'] <br>\n",
    "code2= doc['func2'] <br>\n",
    "prompt= f'''Question: {instruction}\\nCode1: {code1}.\\nCode2: {code2}.\\n\\nAnswer:'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clone detection formatA\n",
    "instruction= '''Is there a clone relation between the Code1 and Code2, and respond to YES or NO.''' <br>\n",
    "code1= doc['func1'] <br>\n",
    "code2= doc['func2'] <br>\n",
    "prompt= f'''Question: Code1: {code1}.\\nCode2: {code2}.\\n{instruction}\\n\\nAnswer:''' <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clone detection formatA 274/1726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 231596.20 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 233492.74 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 203681.71 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 192220.72 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 235823.63 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 160790.80 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 232779.69 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 184114.15 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 184780.66 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 192918.03 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 199373.52 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 130666.07 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 192774.91 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 192583.34 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 135192.94 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 212383.63 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 194268.50 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 206536.84 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 165883.31 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 200629.47 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 165789.50 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 165933.86 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 220808.26 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 194139.86 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 155680.90 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 175905.36 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 201652.08 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 200029.26 examples/s]\n",
      "c:\\Users\\User\\Desktop\\code\\bigcode-evaluation-harness\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 162071.71 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 197684.44 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 276082.31 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 201762.39 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 195203.81 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 186428.71 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 217684.73 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 174323.02 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 238843.41 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 187800.54 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 219979.85 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 129885.30 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 259343.41 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 174123.91 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<?, ? examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 238753.63 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 183655.76 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 109146.80 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 188581.11 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 150963.49 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 191182.56 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 203312.28 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 102618.70 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 299726.65 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 191766.14 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 371174.94 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 178667.89 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 177486.38 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 143053.23 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 219561.65 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 189177.07 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 194572.65 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 171068.01 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 134256.34 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 175320.05 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 196215.49 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 151970.77 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 311179.62 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 177701.54 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 191910.99 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 288554.23 examples/s]\n",
      "Filter: 100%|██████████| 2726/2726 [00:00<00:00, 301600.44 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>%overall_acc</th>\n",
       "      <th>%overall_f1_macro</th>\n",
       "      <th>%valid_rec</th>\n",
       "      <th>%valid_acc</th>\n",
       "      <th>%valid_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lora-1b</td>\n",
       "      <td>10.30</td>\n",
       "      <td>9.30</td>\n",
       "      <td>59.95</td>\n",
       "      <td>17.18</td>\n",
       "      <td>26.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lora-3b</td>\n",
       "      <td>13.70</td>\n",
       "      <td>12.05</td>\n",
       "      <td>100.00</td>\n",
       "      <td>13.70</td>\n",
       "      <td>24.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lora-7b</td>\n",
       "      <td>15.30</td>\n",
       "      <td>14.10</td>\n",
       "      <td>100.00</td>\n",
       "      <td>15.30</td>\n",
       "      <td>24.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lora-15b</td>\n",
       "      <td>14.60</td>\n",
       "      <td>8.80</td>\n",
       "      <td>99.80</td>\n",
       "      <td>14.63</td>\n",
       "      <td>24.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adalora-1b</td>\n",
       "      <td>12.50</td>\n",
       "      <td>8.19</td>\n",
       "      <td>90.75</td>\n",
       "      <td>13.77</td>\n",
       "      <td>22.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adalora-3b</td>\n",
       "      <td>7.20</td>\n",
       "      <td>7.89</td>\n",
       "      <td>12.45</td>\n",
       "      <td>57.83</td>\n",
       "      <td>27.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>adalora-7b</td>\n",
       "      <td>48.20</td>\n",
       "      <td>22.93</td>\n",
       "      <td>55.35</td>\n",
       "      <td>87.08</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adalora-15b</td>\n",
       "      <td>6.80</td>\n",
       "      <td>6.07</td>\n",
       "      <td>19.10</td>\n",
       "      <td>35.60</td>\n",
       "      <td>9.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ia3-1b</td>\n",
       "      <td>12.65</td>\n",
       "      <td>8.28</td>\n",
       "      <td>91.25</td>\n",
       "      <td>13.86</td>\n",
       "      <td>22.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ia3-3b</td>\n",
       "      <td>11.85</td>\n",
       "      <td>11.76</td>\n",
       "      <td>23.15</td>\n",
       "      <td>51.19</td>\n",
       "      <td>25.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ia3-7b</td>\n",
       "      <td>48.40</td>\n",
       "      <td>23.19</td>\n",
       "      <td>56.35</td>\n",
       "      <td>85.89</td>\n",
       "      <td>2.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>prompt-1b</td>\n",
       "      <td>8.75</td>\n",
       "      <td>8.06</td>\n",
       "      <td>58.65</td>\n",
       "      <td>14.92</td>\n",
       "      <td>25.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>prompt-3b</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>prompt-7b</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.10</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>prompt-15b</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ptuning-1b</td>\n",
       "      <td>29.15</td>\n",
       "      <td>19.27</td>\n",
       "      <td>84.95</td>\n",
       "      <td>34.31</td>\n",
       "      <td>18.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ptuning-3b</td>\n",
       "      <td>35.05</td>\n",
       "      <td>23.52</td>\n",
       "      <td>43.80</td>\n",
       "      <td>80.02</td>\n",
       "      <td>27.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ptuning-7b</td>\n",
       "      <td>17.65</td>\n",
       "      <td>13.35</td>\n",
       "      <td>23.55</td>\n",
       "      <td>74.95</td>\n",
       "      <td>19.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ptuning-15b</td>\n",
       "      <td>4.35</td>\n",
       "      <td>3.18</td>\n",
       "      <td>5.00</td>\n",
       "      <td>87.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>parallel-1b</td>\n",
       "      <td>10.75</td>\n",
       "      <td>9.55</td>\n",
       "      <td>61.05</td>\n",
       "      <td>17.61</td>\n",
       "      <td>25.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>parallel-3b</td>\n",
       "      <td>12.35</td>\n",
       "      <td>8.94</td>\n",
       "      <td>80.75</td>\n",
       "      <td>15.29</td>\n",
       "      <td>24.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>parallel-7b</td>\n",
       "      <td>15.90</td>\n",
       "      <td>10.16</td>\n",
       "      <td>97.90</td>\n",
       "      <td>16.24</td>\n",
       "      <td>24.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>parallel-15b</td>\n",
       "      <td>17.80</td>\n",
       "      <td>17.30</td>\n",
       "      <td>100.00</td>\n",
       "      <td>17.80</td>\n",
       "      <td>23.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>adapterp-1b</td>\n",
       "      <td>14.30</td>\n",
       "      <td>8.88</td>\n",
       "      <td>96.75</td>\n",
       "      <td>14.78</td>\n",
       "      <td>24.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>adapterp-3b</td>\n",
       "      <td>14.40</td>\n",
       "      <td>8.63</td>\n",
       "      <td>99.85</td>\n",
       "      <td>14.42</td>\n",
       "      <td>24.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>adapterp-7b</td>\n",
       "      <td>13.70</td>\n",
       "      <td>12.05</td>\n",
       "      <td>100.00</td>\n",
       "      <td>13.70</td>\n",
       "      <td>24.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>adapterp-15b</td>\n",
       "      <td>14.80</td>\n",
       "      <td>9.00</td>\n",
       "      <td>99.70</td>\n",
       "      <td>14.84</td>\n",
       "      <td>24.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>adapterh-1b</td>\n",
       "      <td>12.60</td>\n",
       "      <td>8.59</td>\n",
       "      <td>85.25</td>\n",
       "      <td>14.78</td>\n",
       "      <td>24.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>adapterh-3b</td>\n",
       "      <td>13.85</td>\n",
       "      <td>8.17</td>\n",
       "      <td>99.85</td>\n",
       "      <td>13.87</td>\n",
       "      <td>24.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>adapterh-7b</td>\n",
       "      <td>13.70</td>\n",
       "      <td>12.05</td>\n",
       "      <td>100.00</td>\n",
       "      <td>13.70</td>\n",
       "      <td>24.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>adapterh-15b</td>\n",
       "      <td>13.85</td>\n",
       "      <td>8.18</td>\n",
       "      <td>99.65</td>\n",
       "      <td>13.90</td>\n",
       "      <td>24.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>fft-1b</td>\n",
       "      <td>14.05</td>\n",
       "      <td>8.34</td>\n",
       "      <td>99.85</td>\n",
       "      <td>14.07</td>\n",
       "      <td>24.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>fft-3b</td>\n",
       "      <td>14.20</td>\n",
       "      <td>12.68</td>\n",
       "      <td>100.00</td>\n",
       "      <td>14.20</td>\n",
       "      <td>24.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>fft-7b</td>\n",
       "      <td>13.70</td>\n",
       "      <td>8.04</td>\n",
       "      <td>99.95</td>\n",
       "      <td>13.71</td>\n",
       "      <td>24.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>fft-15b</td>\n",
       "      <td>14.30</td>\n",
       "      <td>12.80</td>\n",
       "      <td>100.00</td>\n",
       "      <td>14.30</td>\n",
       "      <td>24.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      experiment  %overall_acc  %overall_f1_macro  %valid_rec  %valid_acc  \\\n",
       "0        lora-1b         10.30               9.30       59.95       17.18   \n",
       "1        lora-3b         13.70              12.05      100.00       13.70   \n",
       "2        lora-7b         15.30              14.10      100.00       15.30   \n",
       "3       lora-15b         14.60               8.80       99.80       14.63   \n",
       "4     adalora-1b         12.50               8.19       90.75       13.77   \n",
       "5     adalora-3b          7.20               7.89       12.45       57.83   \n",
       "6     adalora-7b         48.20              22.93       55.35       87.08   \n",
       "7    adalora-15b          6.80               6.07       19.10       35.60   \n",
       "8         ia3-1b         12.65               8.28       91.25       13.86   \n",
       "9         ia3-3b         11.85              11.76       23.15       51.19   \n",
       "10        ia3-7b         48.40              23.19       56.35       85.89   \n",
       "11     prompt-1b          8.75               8.06       58.65       14.92   \n",
       "12     prompt-3b          0.00               0.00        0.00        0.00   \n",
       "13     prompt-7b          0.10               0.08        0.10      100.00   \n",
       "14    prompt-15b          0.00               0.00        0.00        0.00   \n",
       "15    ptuning-1b         29.15              19.27       84.95       34.31   \n",
       "16    ptuning-3b         35.05              23.52       43.80       80.02   \n",
       "17    ptuning-7b         17.65              13.35       23.55       74.95   \n",
       "18   ptuning-15b          4.35               3.18        5.00       87.00   \n",
       "19   parallel-1b         10.75               9.55       61.05       17.61   \n",
       "20   parallel-3b         12.35               8.94       80.75       15.29   \n",
       "21   parallel-7b         15.90              10.16       97.90       16.24   \n",
       "22  parallel-15b         17.80              17.30      100.00       17.80   \n",
       "23   adapterp-1b         14.30               8.88       96.75       14.78   \n",
       "24   adapterp-3b         14.40               8.63       99.85       14.42   \n",
       "25   adapterp-7b         13.70              12.05      100.00       13.70   \n",
       "26  adapterp-15b         14.80               9.00       99.70       14.84   \n",
       "27   adapterh-1b         12.60               8.59       85.25       14.78   \n",
       "28   adapterh-3b         13.85               8.17       99.85       13.87   \n",
       "29   adapterh-7b         13.70              12.05      100.00       13.70   \n",
       "30  adapterh-15b         13.85               8.18       99.65       13.90   \n",
       "31        fft-1b         14.05               8.34       99.85       14.07   \n",
       "32        fft-3b         14.20              12.68      100.00       14.20   \n",
       "33        fft-7b         13.70               8.04       99.95       13.71   \n",
       "34       fft-15b         14.30              12.80      100.00       14.30   \n",
       "\n",
       "    %valid_f1  \n",
       "0       26.17  \n",
       "1       24.10  \n",
       "2       24.24  \n",
       "3       24.33  \n",
       "4       22.72  \n",
       "5       27.59  \n",
       "6        1.38  \n",
       "7        9.56  \n",
       "8       22.64  \n",
       "9       25.66  \n",
       "10       2.45  \n",
       "11      25.96  \n",
       "12       0.00  \n",
       "13       0.00  \n",
       "14       0.00  \n",
       "15      18.30  \n",
       "16      27.98  \n",
       "17      19.18  \n",
       "18       0.00  \n",
       "19      25.48  \n",
       "20      24.00  \n",
       "21      24.07  \n",
       "22      23.75  \n",
       "23      24.32  \n",
       "24      24.28  \n",
       "25      24.10  \n",
       "26      24.26  \n",
       "27      24.91  \n",
       "28      24.16  \n",
       "29      24.10  \n",
       "30      24.20  \n",
       "31      24.20  \n",
       "32      24.20  \n",
       "33      24.11  \n",
       "34      24.23  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone_positive = ['there is a','ere is a']\n",
    "clone_negative = ['there is no']\n",
    "\n",
    "cd_path = ['.\\\\run_result\\\\clone_generations_','_fullA.json']\n",
    "\n",
    "print(\"clone detection formatA 274/1726\")\n",
    "summary_table_sampling(file_list,cd_path,274,1726,clone_positive,clone_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_labels</th>\n",
       "      <th>raw_texts</th>\n",
       "      <th>paper_preds</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Yes\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>NO\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Yes\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>0</td>\n",
       "      <td>NO\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes.\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722</th>\n",
       "      <td>0</td>\n",
       "      <td>Yes.\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>1</td>\n",
       "      <td>NO\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>0</td>\n",
       "      <td>Yes\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2308 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     true_labels raw_texts paper_preds preds\n",
       "1              0     Yes\\n           1     1\n",
       "2              0       Yes           1     1\n",
       "4              0        NO           0     0\n",
       "5              1      NO\\n           0     0\n",
       "6              0     Yes\\n           1     1\n",
       "...          ...       ...         ...   ...\n",
       "2720           0      NO\\n           0     0\n",
       "2721           1    Yes.\\n           1     1\n",
       "2722           0    Yes.\\n           1     1\n",
       "2724           1      NO\\n           0     0\n",
       "2725           0     Yes\\n           1     1\n",
       "\n",
       "[2308 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check invalid prediction\n",
    "'''with open('.\\\\run_result\\\\clone_generations_1b-ptuning_fullA.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "clone_positive = ['there is a','ere is a']\n",
    "clone_negative = ['there is no']    \n",
    "raw_texts = [text[0]['raw_text'].split(\"\\nAnswer:\")[-1] for text in data]\n",
    "paper_preds = paper_method(raw_texts,clone_positive,clone_negative)\n",
    "preds = [label[0][\"prediction\"]for label in data]\n",
    "true_labels = [label[0][\"true_label\"]for label in data]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'true_labels': true_labels,\n",
    "    'raw_texts': raw_texts,\n",
    "    'paper_preds': paper_preds,\n",
    "    'preds': preds,\n",
    "})\n",
    "filtered_df = df[df['paper_preds'] != '-1']\n",
    "filtered_df'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
